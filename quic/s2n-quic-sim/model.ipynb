{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba9ef20-ea51-442d-88ca-964020080775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, BoolTensor\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b70d13e2-c756-4787-ae6d-bd8ac6c9036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.transformer import TransformerBlock, CausalAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa03b433-1ca0-47d9-b9f7-b60d660aa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.time2vec import SineActivation, CosineActivation\n",
    "\n",
    "VALID_T2V_ACTIVATION = [\"sin\", \"cos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d6142d-1a76-4775-8954-8788ddb4bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([4, 5, 1])\n",
      "Slice shape: torch.Size([4, 5, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Suppose we have a tensor of shape (B, S, C)\n",
    "B, S, C = 4, 5, 1  # Example dimensions\n",
    "tensor = torch.randn(B, S, C)  # Create a random tensor\n",
    "\n",
    "# Extract the slice [:, :, 0] and retain the singleton dimension\n",
    "slice_tensor = tensor[:, :, 1:]\n",
    "\n",
    "# Check the shape of the resulting tensor\n",
    "print(\"Original shape:\", tensor.shape)  # (B, S, C)\n",
    "print(\"Slice shape:\", slice_tensor.shape)  # (B, S, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bfc106ad-84ac-446a-a99b-4bf2fb7157cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QCCT(nn.Module):\n",
    "    \"\"\"QUIC Congestion Control Transformer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        hidden_size: int,\n",
    "        n_heads: int,\n",
    "        n_layers: int,\n",
    "        expand_size: int,\n",
    "        context_size: int,\n",
    "        t2v_act: str = \"sin\",\n",
    "        act: nn.Module = nn.GELU,\n",
    "        attention: nn.Module = CausalAttention,\n",
    "        drop: float = 0.1,\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Features:\n",
    "        # 1.1 timestamp\n",
    "        if t2v_act == \"sin\":\n",
    "            self.t2v = SineActivation(1, hidden_size)\n",
    "        elif t2v_act == \"cos\":\n",
    "            self.t2v = CosineActivation(1, hidden_size)\n",
    "        else:\n",
    "            raise Exception(f\"Unsupported activation:{t2v_act} for time2vec\")\n",
    "        # 1.2 other features\n",
    "        self.o2v = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(n_features - 1, expand_size, bias=bias),\n",
    "                act(),\n",
    "                nn.Linear(expand_size, hidden_size, bias=bias),\n",
    "                nn.Dropout(drop),\n",
    "            ]\n",
    "        )\n",
    "        # 1.3 feature dropout\n",
    "        self.f_drop = nn.Dropout(drop)\n",
    "\n",
    "        # 2. transformer blocks\n",
    "        # initialize num_layers of transformer layers\n",
    "        self.tfm_blocks = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_heads=n_heads,\n",
    "                    context_size=context_size,\n",
    "                    expand_size=expand_size,\n",
    "                    attention=attention,\n",
    "                    act=act,\n",
    "                    bias=bias,\n",
    "                    attn_drop=drop,\n",
    "                    out_drop=drop,\n",
    "                    ffn_drop=drop,\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 3. output\n",
    "        self.final = nn.Linear(context_size * hidden_size, 1, bias=bias)\n",
    "\n",
    "        # 4. init parameters\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        # [Input]: (B, S, C)\n",
    "        # B: batch_size, S: n_events, C: n_features\n",
    "        B, S, C = x.shape\n",
    "        # Step 1: (B, S, C) -> (B, S, D)\n",
    "        # B: batch_size, S: n_events, D: hidden_size\n",
    "\n",
    "        # Step 1.1: timestamp\n",
    "        # (B, S, 1)\n",
    "        timestamp = x[:, :, 0].unsqueeze(-1)\n",
    "        # (B, S, D)\n",
    "        f_ts = self.t2v(timestamp)\n",
    "\n",
    "        # Step 1.2: other features\n",
    "        # (B, S, C-1)\n",
    "        f_others = x[:, :, 1:]\n",
    "        # (B, S, D)\n",
    "        for layer in self.o2v:\n",
    "            f_others = layer(f_others)\n",
    "\n",
    "        # Step 1.3: Addition\n",
    "        f_all = self.f_drop(f_ts + f_others)\n",
    "        B, S, D = f_all.shape\n",
    "\n",
    "        # Step 2: transformer blocks\n",
    "        for block in self.tfm_blocks:\n",
    "            f_all = block(f_all)\n",
    "\n",
    "        # (B, S, D) -> (B, S * D)\n",
    "        flattened = f_all.view(B, S * D)\n",
    "\n",
    "        # Step 3: next congestion control window\n",
    "        return self.final(flattened)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if module._get_name() == \"fc2\":\n",
    "                # GPT-2 style FFN init\n",
    "                torch.nn.init.normal_(\n",
    "                    module.weight, mean=0.0, std=0.02 / math.sqrt(2 * self.num_layers)\n",
    "                )\n",
    "            else:\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f97f543c-31a2-4ea3-9223-19d60c312bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 8\n",
    "hidden_size = 64\n",
    "n_heads = 4\n",
    "n_layers = 4\n",
    "expand_size = 128\n",
    "context_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cbb38c9a-cabe-45bb-9afe-a4f910577901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QCCT(\n",
       "  (t2v): SineActivation()\n",
       "  (o2v): ModuleList(\n",
       "    (0): Linear(in_features=7, out_features=128, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (f_drop): Dropout(p=0.1, inplace=False)\n",
       "  (tfm_blocks): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalAttention(\n",
       "        (Wqkv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (Wo): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (out_drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QCCT(\n",
    "    n_features=n_features,\n",
    "    hidden_size=hidden_size,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    expand_size=expand_size,\n",
    "    context_size=context_size,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "373c16a5-c5e1-4c45-b8ce-9b663a7ea907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 8])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, S, C = 1, context_size, 8  # Example dimensions\n",
    "tensor = torch.randn(B, S, C)  # Create a random tensor\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "52d92b7e-9f5c-4c2b-8f4b-5e2678a58c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 32 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4377]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cd34b419-57af-4c01-bb4d-7d15f5b7f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_window = df[-2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "15c332a0-5d70-48cf-bb1f-aadce614b07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28040354,        0,       53,       53,        1,        0,\n",
       "               0,        0],\n",
       "       [28040695,        0,       53,        0,        1,        0,\n",
       "               0,        0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_window[-1, -1] = 0\n",
    "test_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e475af70-9703-4228-b6ed-3a5b87494391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, df, window_size, label_column):\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.label_column = label_column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Determine the actual window size based on the index\n",
    "        actual_window_size = min(idx + 1, self.window_size)\n",
    "\n",
    "        # Slice the DataFrame to get the window\n",
    "        start_idx = idx - actual_window_size + 1\n",
    "        window = self.df.iloc[start_idx : idx + 1]\n",
    "\n",
    "        # The label is taken from the last row of the window for the label_column\n",
    "        label = window.iloc[-1][self.label_column]\n",
    "\n",
    "        # Extract the features (all values except the last row's label_column, i.e., the label)\n",
    "        features = window.values\n",
    "        features[-1, -1] = 0\n",
    "\n",
    "        # Pad the features with zeros if necessary\n",
    "        if actual_window_size < self.window_size:\n",
    "            padding = np.zeros(\n",
    "                (self.window_size - actual_window_size, features.shape[1])\n",
    "            )\n",
    "            features = np.vstack((padding, features))\n",
    "\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(\n",
    "            label, dtype=torch.float32\n",
    "        ).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0bf27fe3-e0d0-4d18-a528-580d9bd184bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9663f7d0-bfaa-4978-b109-715b8242e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_dir_tmpl = \"reports_seed_{}\"\n",
    "report_dir_tmpl = \"delay_{}_drop_{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d1bac36-18b7-4921-af7e-167ff185c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "832803e2-22ad-4934-a7d4-83f6010d8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/luzhaoyan/workspace/github/s2n-quic/quic/s2n-quic-sim/reports_seed_42')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the reports directory\n",
    "reports_dir = Path(cwd) / reports_dir_tmpl.format(42)\n",
    "reports_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4fbdcb93-8ce8-4223-8a35-4a24ec5302e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists for delay and drop_rate values\n",
    "delays = [\"5ms\", \"50ms\", \"100ms\", \"200ms\", \"500ms\"]\n",
    "drop_rates = [0.01, 0.05, 0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b287db99-a013-4249-87e4-053f0fdfc379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/luzhaoyan/workspace/github/s2n-quic/quic/s2n-quic-sim/reports_seed_42/delay_200ms_drop_0.05')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dir = reports_dir / report_dir_tmpl.format(delays[3], drop_rates[1])\n",
    "report_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "23ca615e-33fe-4b33-a07c-932b982249ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = report_dir / \"formatted.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "48327b30-6e0d-49de-84e0-0afc9da8c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "245fec07-2bfc-40a9-ba0f-67f211979e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lost_bytes</th>\n",
       "      <th>bytes_acknowledged</th>\n",
       "      <th>bytes_in_filght</th>\n",
       "      <th>event_on_ack</th>\n",
       "      <th>event_on_packet_lost</th>\n",
       "      <th>event_on_packet_sent</th>\n",
       "      <th>congestion_window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>1009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336353</th>\n",
       "      <td>28039944</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336354</th>\n",
       "      <td>28040147</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336355</th>\n",
       "      <td>28040295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336356</th>\n",
       "      <td>28040354</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336357</th>\n",
       "      <td>28040695</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336358 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp  lost_bytes  bytes_acknowledged  bytes_in_filght  \\\n",
       "0             200           0                   0              191   \n",
       "1             200           0                   0             1200   \n",
       "2             600           0                 191             1009   \n",
       "3             600           0                1009                0   \n",
       "4             600           0                   0             1472   \n",
       "...           ...         ...                 ...              ...   \n",
       "336353   28039944           0                  53              106   \n",
       "336354   28040147           0                  53               53   \n",
       "336355   28040295           0                   0              106   \n",
       "336356   28040354           0                  53               53   \n",
       "336357   28040695           0                  53                0   \n",
       "\n",
       "        event_on_ack  event_on_packet_lost  event_on_packet_sent  \\\n",
       "0                  0                     0                     1   \n",
       "1                  0                     0                     1   \n",
       "2                  1                     0                     0   \n",
       "3                  1                     0                     0   \n",
       "4                  0                     0                     1   \n",
       "...              ...                   ...                   ...   \n",
       "336353             1                     0                     0   \n",
       "336354             1                     0                     0   \n",
       "336355             0                     0                     1   \n",
       "336356             1                     0                     0   \n",
       "336357             1                     0                     0   \n",
       "\n",
       "        congestion_window  \n",
       "0                   12000  \n",
       "1                   12000  \n",
       "2                   12000  \n",
       "3                   12000  \n",
       "4                   12000  \n",
       "...                   ...  \n",
       "336353              10066  \n",
       "336354              10066  \n",
       "336355              10066  \n",
       "336356              10066  \n",
       "336357              10066  \n",
       "\n",
       "[336358 rows x 8 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "10d62036-876a-444f-99fd-e8d2efc0f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_features = 8\n",
    "hidden_size = 64\n",
    "n_heads = 4\n",
    "n_layers = 4\n",
    "expand_size = 128\n",
    "context_size = 32\n",
    "window_size = context_size\n",
    "batch_size = 128\n",
    "label_column = \"congestion_window\"\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d9b7cdb4-f608-48fa-89bc-d7542cfda43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and data loader\n",
    "dataset = SlidingWindowDataset(df, window_size, label_column)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d7a0c610-6c99-4b3f-a159-5708c6a18a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming you have a model defined as 'model'\n",
    "model = QCCT(\n",
    "    n_features=n_features,\n",
    "    hidden_size=hidden_size,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    expand_size=expand_size,\n",
    "    context_size=context_size,\n",
    ")\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Define the criterion (loss function)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (e.g., Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c82c9-11a4-478e-8226-7fff3266a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|████████████████████████████████████████████████▊| 2615/2628 [05:38<00:01,  8.37batch/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Import tqdm for progress visualization\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for features, label in tqdm(\n",
    "        data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"\n",
    "    ):\n",
    "        features, label = features.to(device), label.to(device)\n",
    "        # print(features.shape, label.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        # print(outputs.shape)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75155ad-4de0-4049-ab0f-f187b5fc3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example = torch.rand(1, context_size, 8)\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363431aa-3103-438d-a7d9-6afc7a8b9252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
